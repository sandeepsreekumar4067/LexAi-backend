[
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain.text_splitter",
        "description": "langchain.text_splitter",
        "isExtraImport": true,
        "detail": "langchain.text_splitter",
        "documentation": {}
    },
    {
        "label": "OllamaEmbeddings",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "ChatOllama",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "OllamaEmbeddings",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_community.vectorstores",
        "description": "langchain_community.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_community.vectorstores",
        "documentation": {}
    },
    {
        "label": "OllamaLLM",
        "importPath": "langchain_ollama.llms",
        "description": "langchain_ollama.llms",
        "isExtraImport": true,
        "detail": "langchain_ollama.llms",
        "documentation": {}
    },
    {
        "label": "OllamaLLM",
        "importPath": "langchain_ollama.llms",
        "description": "langchain_ollama.llms",
        "isExtraImport": true,
        "detail": "langchain_ollama.llms",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "Chroma",
        "importPath": "langchain_chroma",
        "description": "langchain_chroma",
        "isExtraImport": true,
        "detail": "langchain_chroma",
        "documentation": {}
    },
    {
        "label": "ConversationBufferMemory",
        "importPath": "langchain.memory",
        "description": "langchain.memory",
        "isExtraImport": true,
        "detail": "langchain.memory",
        "documentation": {}
    },
    {
        "label": "HumanMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "AIMessage",
        "importPath": "langchain_core.messages",
        "description": "langchain_core.messages",
        "isExtraImport": true,
        "detail": "langchain_core.messages",
        "documentation": {}
    },
    {
        "label": "cosine_similarity",
        "importPath": "sklearn.metrics.pairwise",
        "description": "sklearn.metrics.pairwise",
        "isExtraImport": true,
        "detail": "sklearn.metrics.pairwise",
        "documentation": {}
    },
    {
        "label": "handle_query",
        "kind": 2,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "def handle_query(query, context=\"\"):\n    # If document search is triggered\n    if \"section\" in query.lower() or \"pdf\" in query.lower():\n        results = vector_store.similarity_search(query)\n        if results:\n            context = results[0].page_content  # Add the first result to the context\n    # Construct the full prompt with context and query\n    full_prompt = chat_prompt.format(query=query, context=context)\n    return llm.invoke(full_prompt)\n# Example usage",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "llm = OllamaLLM(model=\"llama3.1\")\nembedding_model = OllamaEmbeddings(model=\"llama3.1\")\n# uploading the pdf\nprint(\"uploaded the pdf\")\npdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = ChatPromptTemplate.from_messages([\n    \"\"\"\n    <s>[INST] You are an AI legal assistant, skilled in Indian law. Provide accurate legal advice or document lookup based on the query. If you do not have sufficient information to answer, please advise on the next steps or suggest seeking professional legal help. [/INST]</s>\n    [INST] Question: {query}",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "embedding_model",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\n# uploading the pdf\nprint(\"uploaded the pdf\")\npdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = ChatPromptTemplate.from_messages([\n    \"\"\"\n    <s>[INST] You are an AI legal assistant, skilled in Indian law. Provide accurate legal advice or document lookup based on the query. If you do not have sufficient information to answer, please advise on the next steps or suggest seeking professional legal help. [/INST]</s>\n    [INST] Question: {query}\n           Context: {context}",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "pdf_reader",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "pdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = ChatPromptTemplate.from_messages([\n    \"\"\"\n    <s>[INST] You are an AI legal assistant, skilled in Indian law. Provide accurate legal advice or document lookup based on the query. If you do not have sufficient information to answer, please advise on the next steps or suggest seeking professional legal help. [/INST]</s>\n    [INST] Question: {query}\n           Context: {context}\n           Response:\n    [/INST]\n\"\"\"",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "documents",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "documents = pdf_reader.load_and_split()\nchat_prompt = ChatPromptTemplate.from_messages([\n    \"\"\"\n    <s>[INST] You are an AI legal assistant, skilled in Indian law. Provide accurate legal advice or document lookup based on the query. If you do not have sufficient information to answer, please advise on the next steps or suggest seeking professional legal help. [/INST]</s>\n    [INST] Question: {query}\n           Context: {context}\n           Response:\n    [/INST]\n\"\"\"\n])",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "chat_prompt",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "chat_prompt = ChatPromptTemplate.from_messages([\n    \"\"\"\n    <s>[INST] You are an AI legal assistant, skilled in Indian law. Provide accurate legal advice or document lookup based on the query. If you do not have sufficient information to answer, please advise on the next steps or suggest seeking professional legal help. [/INST]</s>\n    [INST] Question: {query}\n           Context: {context}\n           Response:\n    [/INST]\n\"\"\"\n])\nprint(\"creating the text splitter\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "text_splitter",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1024, chunk_overlap=200, length_function=len\n)\n# creating the chunks\nprint(\"creating the chunks\")\nchunks = text_splitter.split_documents(documents)\nprint(\"creating chroma db\")\n# creating the vector store\n# vector_store = Chroma.from_documents(\n#     chunks, embedding_model, persist_directory=\"db\"",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "chunks = text_splitter.split_documents(documents)\nprint(\"creating chroma db\")\n# creating the vector store\n# vector_store = Chroma.from_documents(\n#     chunks, embedding_model, persist_directory=\"db\"\n# )\n# Load the existing Chroma vector store\n# vector_store = Chroma(persist_directory=\"db\", embedding_function=embedding_model.embed_query)\nvector_store = Chroma(persist_directory=\"db\", embedding_function=embedding_model)\nprint(\"Chroma DB loaded successfully\")",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "vector_store",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "vector_store = Chroma(persist_directory=\"db\", embedding_function=embedding_model)\nprint(\"Chroma DB loaded successfully\")\ndef handle_query(query, context=\"\"):\n    # If document search is triggered\n    if \"section\" in query.lower() or \"pdf\" in query.lower():\n        results = vector_store.similarity_search(query)\n        if results:\n            context = results[0].page_content  # Add the first result to the context\n    # Construct the full prompt with context and query\n    full_prompt = chat_prompt.format(query=query, context=context)",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "chat_history",
        "kind": 5,
        "importPath": "app",
        "description": "app",
        "peekOfCode": "chat_history = []\nwhile True:\n    user_query = input(\"Ask your question: \")\n    if user_query.lower() == \"exit\":\n        break\n    # Add previous conversation to context\n    context = \" \".join(chat_history)\n    # Handle the query\n    response = handle_query(user_query, context)\n    # Update chat history",
        "detail": "app",
        "documentation": {}
    },
    {
        "label": "is_relevant_below_threshold",
        "kind": 2,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "def is_relevant_below_threshold(docs,threshold):\n    for doc,score in docs:\n        if score < threshold:\n            d.append({\n                \"status\":\"irrelevant docs\",\n                \"result\":docs,\n                \"score\":score\n            })\n            return d\n        else:",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "classify_query",
        "kind": 2,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "def classify_query(query):\n    # Embed the query\n    query_embedding = embedding_model.embed_documents([query])\n    # Calculate similarities\n    legal_similarity = cosine_similarity(query_embedding, legal_embeddings)\n    casual_similarity = cosine_similarity(query_embedding, casual_embeddings)\n    # Get the maximum similarity score for legal and casual categories\n    max_legal_similarity = max(legal_similarity[0])\n    max_casual_similarity = max(casual_similarity[0])\n    # Set a threshold for classifying the query",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "handle_query",
        "kind": 2,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "def handle_query(query):\n    query_type = classify_query(query)\n    if query_type[\"status\"] == \"casual\":\n        # If casual, handle the query normally with LLM\n        context=\"the user wants to have a casual chat\"\n        casual_prompt = chat_prompt.format(input=query,context=context)\n        docs = llm.invoke(casual_prompt)\n    else:\n        # If legal, perform similarity search in Chroma for relevant docs\n        relevant_docs = vector_store.similarity_search_with_score(query, k=10)",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "llm",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "llm = ChatOllama(model=\"llama3.1\",temperature=0.7,)\nembedding_model = OllamaEmbeddings(model=\"llama3.1\")\nchat_history=[]\n# uploading the pdf\nprint(\"uploaded the pdf\")\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\npdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = PromptTemplate.from_template(\n        \"\"\"",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "embedding_model",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "embedding_model = OllamaEmbeddings(model=\"llama3.1\")\nchat_history=[]\n# uploading the pdf\nprint(\"uploaded the pdf\")\nmemory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\npdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = PromptTemplate.from_template(\n        \"\"\"\n        You are an AI Legal Assistant Skilled in Indian Law,Your name is LexAi ,Also you are a very Friendly Chat Bot .",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "memory",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\npdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = PromptTemplate.from_template(\n        \"\"\"\n        You are an AI Legal Assistant Skilled in Indian Law,Your name is LexAi ,Also you are a very Friendly Chat Bot .\n        So for each user query provide ACCURATE,USEFUL,THOUGHTFUL Response.\n        also if the user intends to do normal Chatting ; initiate in friendly chatting too,\n        But Remind them of your PURPOSE and ROLE if the user initiates only FRIENDLY CHAT and make them engage in Asking LEGAL QUERIES\n        on Indian Peanal Code",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "pdf_reader",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "pdf_reader = PyPDFLoader(\"../Backend/assets/ipc.pdf\")\ndocuments = pdf_reader.load_and_split()\nchat_prompt = PromptTemplate.from_template(\n        \"\"\"\n        You are an AI Legal Assistant Skilled in Indian Law,Your name is LexAi ,Also you are a very Friendly Chat Bot .\n        So for each user query provide ACCURATE,USEFUL,THOUGHTFUL Response.\n        also if the user intends to do normal Chatting ; initiate in friendly chatting too,\n        But Remind them of your PURPOSE and ROLE if the user initiates only FRIENDLY CHAT and make them engage in Asking LEGAL QUERIES\n        on Indian Peanal Code\n        Question: {input}",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "documents",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "documents = pdf_reader.load_and_split()\nchat_prompt = PromptTemplate.from_template(\n        \"\"\"\n        You are an AI Legal Assistant Skilled in Indian Law,Your name is LexAi ,Also you are a very Friendly Chat Bot .\n        So for each user query provide ACCURATE,USEFUL,THOUGHTFUL Response.\n        also if the user intends to do normal Chatting ; initiate in friendly chatting too,\n        But Remind them of your PURPOSE and ROLE if the user initiates only FRIENDLY CHAT and make them engage in Asking LEGAL QUERIES\n        on Indian Peanal Code\n        Question: {input}\n        Context: {context}",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "chat_prompt",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "chat_prompt = PromptTemplate.from_template(\n        \"\"\"\n        You are an AI Legal Assistant Skilled in Indian Law,Your name is LexAi ,Also you are a very Friendly Chat Bot .\n        So for each user query provide ACCURATE,USEFUL,THOUGHTFUL Response.\n        also if the user intends to do normal Chatting ; initiate in friendly chatting too,\n        But Remind them of your PURPOSE and ROLE if the user initiates only FRIENDLY CHAT and make them engage in Asking LEGAL QUERIES\n        on Indian Peanal Code\n        Question: {input}\n        Context: {context}\n        Response:",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "legal_check_template",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "legal_check_template = ChatPromptTemplate.from_template(\n    \"\"\"\n    You are an AI Legal Assistant. A legal question typically contains terms related to laws, sections, or legal topics.\n    A query like 'Can you explain Section 420 of IPC?' is a legal query.\n    \"\"\"\n)\nprint(\"creating the text splitter\")\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1024, chunk_overlap=200, length_function=len\n)",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "text_splitter",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "text_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1024, chunk_overlap=200, length_function=len\n)\n# creating the chunks\nprint(\"creating the chunks\")\nchunks = text_splitter.split_documents(documents)\nprint(\"creating chroma db\")\nvector_store = Chroma(persist_directory=\"db\", embedding_function=embedding_model)\nprint(\"Chroma DB loaded successfully\")\nthreshold = 1.4",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "chunks",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "chunks = text_splitter.split_documents(documents)\nprint(\"creating chroma db\")\nvector_store = Chroma(persist_directory=\"db\", embedding_function=embedding_model)\nprint(\"Chroma DB loaded successfully\")\nthreshold = 1.4\nd = []\ndef is_relevant_below_threshold(docs,threshold):\n    for doc,score in docs:\n        if score < threshold:\n            d.append({",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "vector_store",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "vector_store = Chroma(persist_directory=\"db\", embedding_function=embedding_model)\nprint(\"Chroma DB loaded successfully\")\nthreshold = 1.4\nd = []\ndef is_relevant_below_threshold(docs,threshold):\n    for doc,score in docs:\n        if score < threshold:\n            d.append({\n                \"status\":\"irrelevant docs\",\n                \"result\":docs,",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "threshold",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "threshold = 1.4\nd = []\ndef is_relevant_below_threshold(docs,threshold):\n    for doc,score in docs:\n        if score < threshold:\n            d.append({\n                \"status\":\"irrelevant docs\",\n                \"result\":docs,\n                \"score\":score\n            })",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "d = []\ndef is_relevant_below_threshold(docs,threshold):\n    for doc,score in docs:\n        if score < threshold:\n            d.append({\n                \"status\":\"irrelevant docs\",\n                \"result\":docs,\n                \"score\":score\n            })\n            return d",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "examples",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "examples = {\n    \"legal\": [\n        \"What is Section 420 of the Indian Penal Code?\",\n        \"Can you explain the punishment for theft under IPC?\",\n        \"Tell me about bail provisions in Indian law.\",\n        \"What are the laws regarding domestic violence?\",\n        \"How do I file a complaint for defamation?\",\n        \"What is the penalty for cybercrime in India?\",\n        \"Explain the law on trespassing in India.\",\n        \"What are the conditions for anticipatory bail?\",",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "legal_embeddings",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "legal_embeddings = embedding_model.embed_documents(examples[\"legal\"])\ncasual_embeddings = embedding_model.embed_documents(examples[\"casual\"])\n# Function to calculate similarity with the dictionary\ndef classify_query(query):\n    # Embed the query\n    query_embedding = embedding_model.embed_documents([query])\n    # Calculate similarities\n    legal_similarity = cosine_similarity(query_embedding, legal_embeddings)\n    casual_similarity = cosine_similarity(query_embedding, casual_embeddings)\n    # Get the maximum similarity score for legal and casual categories",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "casual_embeddings",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "casual_embeddings = embedding_model.embed_documents(examples[\"casual\"])\n# Function to calculate similarity with the dictionary\ndef classify_query(query):\n    # Embed the query\n    query_embedding = embedding_model.embed_documents([query])\n    # Calculate similarities\n    legal_similarity = cosine_similarity(query_embedding, legal_embeddings)\n    casual_similarity = cosine_similarity(query_embedding, casual_embeddings)\n    # Get the maximum similarity score for legal and casual categories\n    max_legal_similarity = max(legal_similarity[0])",
        "detail": "casualBot",
        "documentation": {}
    },
    {
        "label": "chat_history",
        "kind": 5,
        "importPath": "casualBot",
        "description": "casualBot",
        "peekOfCode": "chat_history = []\nwhile True:\n    query = input(\"Ask your question: \")\n    if query.lower() == \"bye\":\n        break\n    response = handle_query(query)\n    handle_query(query)\n    print(\"\\nAI Response:\\n\")\n    print(response)\n    print(\"\\n------------------------------------\\n\")",
        "detail": "casualBot",
        "documentation": {}
    }
]