if is_relevant(relevant_docs,0.5):
    #     response = llm.invoke(query)
    # else:
    #     context = ''.join([doc[0].page_content for doc in relevant_docs])
    #     full_prompt = chat_prompt.format(input=query,context=context)
    #     response = llm.invoke(full_prompt)